{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqV4O5U1xvFo"
      },
      "source": [
        "# Clone Github Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvH9ffwmNWiP",
        "outputId": "0ebe5c49-50ba-49cc-f799-619bf8425c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LPRNet_Pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sirius-ai/LPRNet_Pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvvRWAA5NaL-",
        "outputId": "b9260ff9-3cae-40de-9f6b-c99b92a22a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights/Final_LPRNet_model.pth: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/sirius-ai/LPRNet_Pytorch/raw/master/weights/Final_LPRNet_model.pth -O weights/Final_LPRNet_model.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzgy4KPgZwC4"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WjMJcSZKNjo",
        "outputId": "f0f3a4cc-bb47-41f2-ee63-ccedca81471b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://mlc.ai/wheels\n",
            "Requirement already satisfied: mlc-ai-cpu in /usr/local/lib/python3.10/dist-packages (0.17.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (3.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (1.13.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m  pip install mlc-ai-cpu -f https://mlc.ai/wheels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5GUHwRpKqtu",
        "outputId": "93cf8e8d-8c2c-4059-e625-b3b22dd1ab83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tvm in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from tvm) (1.4.4)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from tvm) (0.6.2)\n",
            "Requirement already satisfied: inform in /usr/local/lib/python3.10/dist-packages (from tvm) (1.32)\n",
            "Requirement already satisfied: quantiphy in /usr/local/lib/python3.10/dist-packages (from tvm) (2.20)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from inform->tvm) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from inform->tvm) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->inform->tvm) (2.8.2)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->inform->tvm) (2.9.0.20241206)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tvm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_3m7yvVKw80",
        "outputId": "57c5fe60-6733-4b0d-c13c-b657d65d5621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing torchprofile...\n",
            "All required packages have been successfully installed!\n"
          ]
        }
      ],
      "source": [
        "print('Installing torchprofile...')\n",
        "!pip install torchprofile 1>/dev/null\n",
        "print('All required packages have been successfully installed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JWHyqHiNFZM",
        "outputId": "065131e7-0916-46ca-c0e3-2857beb2b0c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision numpy opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSyf0PCDuOBb",
        "outputId": "99f62722-338f-46fb-a8ed-01005ec9c6de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmmV-chtNXJi",
        "outputId": "23bee4ab-a06e-48b3-ae4a-7cfe80f0def1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LPRNet_Pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/LPRNet_Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUt0w5I5LHPu"
      },
      "source": [
        "#Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n-x3r6jPLD22"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from model.LPRNet import LPRNet\n",
        "from data.load_data import LPRDataLoader, CHARS\n",
        "\n",
        "\n",
        "from data.load_data import CHARS, CHARS_DICT, LPRDataLoader\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from model.LPRNet import build_lprnet, small_basic_block\n",
        "# import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import *\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.sparse as sparse\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import argparse\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import *\n",
        "from data.load_data import LPRDataLoader, CHARS\n",
        "from model.LPRNet import build_lprnet\n",
        "\n",
        "import torch.quantization\n",
        "import torch.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxOD8o9wJUEl"
      },
      "source": [
        "#LPRNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-9g5FFdJTGE",
        "outputId": "2e43e595-7b9d-41b0-d2b0-05143b402e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LPRNet model loaded successfully.\n",
            "Model is on device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-eaddd8717b46>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(weights_path, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "lpr_max_len = 8\n",
        "# Set up the device\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cpu\"\n",
        "# Initialize the model\n",
        "lprnet = LPRNet(lpr_max_len=lpr_max_len, class_num=len(CHARS), dropout_rate=0, phase=\"eval\")\n",
        "\n",
        "# Load the pre-trained weights\n",
        "weights_path = 'weights/Final_LPRNet_model.pth'\n",
        "state_dict = torch.load(weights_path, map_location=device)\n",
        "lprnet.load_state_dict(state_dict)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "lprnet = lprnet.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "lprnet.eval()\n",
        "\n",
        "print(\"LPRNet model loaded successfully.\")\n",
        "print(f\"Model is on device: {next(lprnet.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uqU-hxfDU72-"
      },
      "outputs": [],
      "source": [
        "test_img_dirs = [\"data/test\"]\n",
        "test_dataset = LPRDataLoader(test_img_dirs, imgSize=(94, 24), lpr_max_len=lpr_max_len)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FfyKr4wIV87f"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    lengths = []\n",
        "    for _, sample in enumerate(batch):\n",
        "        img, label, length = sample\n",
        "        imgs.append(torch.from_numpy(img))\n",
        "        labels.extend(label)\n",
        "        lengths.append(length)\n",
        "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
        "\n",
        "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_Oa9IepTT-YP"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "def get_parser_test():\n",
        "    parser = argparse.ArgumentParser(description='parameters to train net')\n",
        "    parser.add_argument('--img_size', default=[94, 24], help='the image size')\n",
        "    parser.add_argument('--test_img_dirs', default=\"./data/test\", help='the test images path')\n",
        "    parser.add_argument('--dropout_rate', default=0, help='dropout rate.')\n",
        "    parser.add_argument('--lpr_max_len', default=8, help='license plate number max length.')\n",
        "    parser.add_argument('--test_batch_size', default=100, help='testing batch size.')\n",
        "    parser.add_argument('--phase_train', default=False, type=bool, help='train or test phase flag.')\n",
        "    parser.add_argument('--num_workers', default=8, type=int, help='Number of workers used in dataloading')\n",
        "    parser.add_argument('--cuda', default=False, type=bool, help='Use cuda to train model')\n",
        "    parser.add_argument('--show', default=False, type=bool, help='show test image and its predict result or not.')\n",
        "    parser.add_argument('--pretrained_model', default='./weights/Final_LPRNet_model.pth', help='pretrained base model')\n",
        "\n",
        "    # Parse arguments with an empty list to avoid reading from sys.argv\n",
        "    args = parser.parse_args(args=[])\n",
        "\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XLH8779ycwwN"
      },
      "outputs": [],
      "source": [
        "def Greedy_Decode_Eval(Net, datasets, args):\n",
        "    # TestNet = Net.eval()\n",
        "    epoch_size = len(datasets) // args.test_batch_size\n",
        "    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n",
        "\n",
        "    Tp = 0\n",
        "    Tn_1 = 0\n",
        "    Tn_2 = 0\n",
        "    t1 = time.time()\n",
        "    for i in range(epoch_size):\n",
        "        # load train data\n",
        "        images, labels, lengths = next(batch_iterator)\n",
        "        start = 0\n",
        "        targets = []\n",
        "\n",
        "        for length in lengths:\n",
        "            label = labels[start:start+length]\n",
        "            targets.append(label)\n",
        "            start += length\n",
        "        targets = np.array([el.numpy() for el in targets])\n",
        "        imgs = images.numpy().copy()\n",
        "\n",
        "        if args.cuda:\n",
        "            images = Variable(images.cuda())\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "\n",
        "        # forward\n",
        "        # forward\n",
        "        with torch.no_grad():\n",
        "          prebs = Net(images)\n",
        "        # greedy decode\n",
        "        prebs = prebs.cpu().detach().numpy()\n",
        "        preb_labels = list()\n",
        "        for i in range(prebs.shape[0]):\n",
        "            preb = prebs[i, :, :]\n",
        "            preb_label = list()\n",
        "            for j in range(preb.shape[1]):\n",
        "                preb_label.append(np.argmax(preb[:, j], axis=0))\n",
        "            no_repeat_blank_label = list()\n",
        "            pre_c = preb_label[0]\n",
        "            if pre_c != len(CHARS) - 1:\n",
        "                no_repeat_blank_label.append(pre_c)\n",
        "            for c in preb_label: # dropout repeate label and blank label\n",
        "                if (pre_c == c) or (c == len(CHARS) - 1):\n",
        "                    if c == len(CHARS) - 1:\n",
        "                        pre_c = c\n",
        "                    continue\n",
        "                no_repeat_blank_label.append(c)\n",
        "                pre_c = c\n",
        "            preb_labels.append(no_repeat_blank_label)\n",
        "        for i, label in enumerate(preb_labels):\n",
        "            # show image and its predict label\n",
        "            if args.show:\n",
        "                show(imgs[i], label, targets[i])\n",
        "            if len(label) != len(targets[i]):\n",
        "                Tn_1 += 1\n",
        "                continue\n",
        "            if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
        "                Tp += 1\n",
        "            else:\n",
        "                Tn_2 += 1\n",
        "    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
        "\n",
        "    t2 = time.time()\n",
        "    print(\"[Info] Test Speed: {}s 1/{}]\".format((t2 - t1) / len(datasets), len(datasets)))\n",
        "    return Acc, (t2 - t1) / len(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajw6EYdc2E4t",
        "outputId": "f4b228f4-c161-4580-b0d5-29e4dca3e20c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Speed: 0.20374352216720581s 1/1000]\n"
          ]
        }
      ],
      "source": [
        "args = get_parser_test()\n",
        "baseline_accuracy, baseline_test_speed = Greedy_Decode_Eval(lprnet, test_dataset, args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVVPXHqntzBT"
      },
      "source": [
        "#Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YR83SKtMZnRD"
      },
      "outputs": [],
      "source": [
        "def structured_prune_conv(module, name, amount):\n",
        "    if not isinstance(module, nn.Conv2d):\n",
        "        return\n",
        "\n",
        "    weight = getattr(module, name)\n",
        "    output_channels = weight.shape[0]\n",
        "    num_prune = int(output_channels * amount)\n",
        "\n",
        "    # Calculate L1-norm for each filter\n",
        "    l1_norm = torch.sum(torch.abs(weight.view(output_channels, -1)), dim=1)\n",
        "\n",
        "    # Get indices of filters to keep (those with highest L1-norm)\n",
        "    top_k = torch.topk(l1_norm, output_channels - num_prune, largest=True, sorted=False)\n",
        "    mask = torch.zeros_like(l1_norm)\n",
        "    mask[top_k.indices] = 1\n",
        "\n",
        "    # Create a sparse mask\n",
        "    sparse_mask = mask.to_sparse()\n",
        "\n",
        "    # Apply the mask to the weight tensor\n",
        "    pruned_weight = weight * mask.view(-1, 1, 1, 1)\n",
        "\n",
        "    # Set the pruned weights back to the module\n",
        "    setattr(module, name, nn.Parameter(pruned_weight))\n",
        "\n",
        "    # Save the mask for future reference\n",
        "    module.register_buffer(f'{name}_mask', sparse_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ENZrae0vcmo",
        "outputId": "faca3fb9-a30e-4f20-ce1c-730426052fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LPRNet model deepcopied successfully.\n",
            "Model is on device: cpu\n"
          ]
        }
      ],
      "source": [
        "lprnet_copy = copy.deepcopy(lprnet)\n",
        "\n",
        "print(\"LPRNet model deepcopied successfully.\")\n",
        "print(f\"Model is on device: {next(lprnet_copy.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yaaJZ1BDtx7D"
      },
      "outputs": [],
      "source": [
        "def prune_model(model, amount=0.1):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            structured_prune_conv(module, 'weight', amount)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEGdXthetyZY",
        "outputId": "4a3a83d0-654e-4b0d-c28f-b479adb5a745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished pruning the model\n"
          ]
        }
      ],
      "source": [
        "# Prune the model\n",
        "pruned_lprnet = prune_model(lprnet_copy, amount=0.01)\n",
        "\n",
        "print(\"Finished pruning the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1iSzo7Vvb-w",
        "outputId": "ed7c4c13-16ab-4be0-fccb-3d60e10f1b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Speed: 0.1872528645992279s 1/1000]\n"
          ]
        }
      ],
      "source": [
        "args = get_parser_test()\n",
        "pruned_accuracy, pruned_test_speed = Greedy_Decode_Eval(pruned_lprnet, test_dataset, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQZUbYVoEeYZ",
        "outputId": "5ead480a-6ac3-4dab-fa38-c13b4c893541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LPRNet(\n",
              "  (backbone): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU()\n",
              "    (11): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Dropout(p=0, inplace=False)\n",
              "    (16): Conv2d(64, 256, kernel_size=(1, 4), stride=(1, 1))\n",
              "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (18): ReLU()\n",
              "    (19): Dropout(p=0, inplace=False)\n",
              "    (20): Conv2d(256, 68, kernel_size=(13, 1), stride=(1, 1))\n",
              "    (21): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU()\n",
              "  )\n",
              "  (container): Sequential(\n",
              "    (0): Conv2d(516, 68, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "pruned_lprnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2RCy3Z63Gfw"
      },
      "source": [
        "## Fine-tuning attempt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zlT7XnDxw5yN"
      },
      "outputs": [],
      "source": [
        "# import argparse\n",
        "\n",
        "# def get_parser_train():\n",
        "#     parser = argparse.ArgumentParser(description='parameters to train net')\n",
        "#     parser.add_argument('--max_epoch', default=4, help='epoch to train the network')\n",
        "#     parser.add_argument('--img_size', default=[94, 24], help='the image size')\n",
        "#     parser.add_argument('--train_img_dirs', default=\"./data/train\", help='the train images path')\n",
        "#     parser.add_argument('--test_img_dirs', default=\"./data/test\", help='the test images path')\n",
        "#     parser.add_argument('--dropout_rate', default=0.5, help='dropout rate.')\n",
        "#     parser.add_argument('--learning_rate', default=0.001, help='learning rate')\n",
        "#     parser.add_argument('--lpr_max_len', default=8, help='license plate number max length')\n",
        "#     parser.add_argument('--train_batch_size', default=128, help='training batch size')\n",
        "#     parser.add_argument('--test_batch_size', default=128, help='testing batch size')\n",
        "#     parser.add_argument('--phase_train', default=True, type=bool, help='train or test phase flag')\n",
        "#     parser.add_argument('--num_workers', default=8, type=int, help='Number of workers used in dataloading')\n",
        "#     parser.add_argument('--cuda', default=True, type=bool, help='Use cuda to train model')\n",
        "#     parser.add_argument('--resume_epoch', default=0, type=int, help='resume iter for retraining')\n",
        "#     parser.add_argument('--save_interval', default=1000, type=int, help='interval for save model state dict')\n",
        "#     parser.add_argument('--test_interval', default=2000, type=int, help='interval for evaluate')\n",
        "#     parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
        "#     parser.add_argument('--weight_decay', default=2e-5, type=float, help='Weight decay for SGD')\n",
        "#     parser.add_argument('--lr_schedule', default=[4, 8], help='schedule for learning rate.')\n",
        "#     parser.add_argument('--save_folder', default='./weights/', help='Location to save checkpoint models')\n",
        "#     parser.add_argument('--pretrained_model', default='./weights/Final_LPRNet_model.pth', help='pretrained base model')\n",
        "#     args = parser.parse_args(args=[])\n",
        "\n",
        "#     return args\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "II3dLLEEWW6a"
      },
      "outputs": [],
      "source": [
        "# def train(lprnet):\n",
        "#     args = get_parser_train()\n",
        "\n",
        "#     # Load the pruned model\n",
        "#     # lprnet = torch.load('path_to_your_pruned_model.pth')\n",
        "#     # lprnet = lprnet.to(device)\n",
        "\n",
        "#     train_dataset = LPRDataLoader(args.train_img_dirs.split(','), args.img_size, args.lpr_max_len)\n",
        "#     trainloader = DataLoader(train_dataset, batch_size=args.train_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn)\n",
        "\n",
        "#     criterion = nn.CTCLoss(blank=len(CHARS)-1, reduction='mean')\n",
        "#     optimizer = optim.RMSprop(lprnet.parameters(), lr=args.learning_rate * 0.1, alpha=0.9, eps=1e-08, weight_decay=args.weight_decay, momentum=args.momentum)\n",
        "#     train_loss = 0\n",
        "#     cnt = 0\n",
        "#     for epoch in range(args.max_epoch):\n",
        "#         for i, (imgs, labels, lengths) in enumerate(trainloader):\n",
        "#             imgs, labels = imgs.to(device), labels.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             transfer = lprnet(imgs)\n",
        "#             log_probs = transfer.permute(2, 0, 1)\n",
        "#             log_probs = log_probs.log_softmax(2).requires_grad_()\n",
        "#             input_lengths = torch.full((log_probs.size(1),), log_probs.size(0), dtype=torch.long)\n",
        "#             target_lengths = torch.from_numpy(np.array(lengths)).type(torch.long)\n",
        "#             loss = criterion(log_probs, labels, input_lengths, target_lengths)\n",
        "#             loss.backward()\n",
        "\n",
        "#             # Apply masks to gradients\n",
        "#             for name, module in lprnet.named_modules():\n",
        "#                 if isinstance(module, nn.Conv2d) and hasattr(module, 'weight_mask'):\n",
        "#                     module.weight.grad *= module.weight_mask\n",
        "\n",
        "#             optimizer.step()\n",
        "\n",
        "#             train_loss += loss.item()\n",
        "#             cnt += 1\n",
        "\n",
        "#             if i % 100 == 0:\n",
        "#                 print(f'Epoch [{epoch+1}/{args.max_epoch}], Iter [{i+1}/{len(trainloader)}], Loss: {train_loss/cnt:.4f}')\n",
        "#                 train_loss = 0\n",
        "#                 cnt = 0\n",
        "\n",
        "#         # Save model\n",
        "#         if (epoch + 1) % args.save_interval == 0:\n",
        "#             test_args = get_parser_test()\n",
        "#             print(Greedy_Decode_Eval(lprnet, test_dataset, test_args))\n",
        "#             #torch.save(lprnet.state_dict(), args.save_folder + 'LPRNet_' + str(epoch + 1) + '.pth')\n",
        "\n",
        "#     print(Greedy_Decode_Eval(lprnet, test_dataset, args))\n",
        "#     # Final save\n",
        "#     # torch.save(lprnet.state_dict(), args.save_folder + 'Final_LPRNet_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "QQ-RjnGhXFaC"
      },
      "outputs": [],
      "source": [
        "# device = \"cpu\"\n",
        "# train(lprnet_copy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptR718053DXG"
      },
      "source": [
        "#Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v3Nqfq_kXGrn"
      },
      "outputs": [],
      "source": [
        "class QuantizableLPRNet(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super().__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "        self.model = self.modify_model(original_model)\n",
        "\n",
        "    def modify_model(self, model):\n",
        "        for name, module in model.named_children():\n",
        "            if isinstance(module, nn.MaxPool3d):\n",
        "                class ContiguousModule(nn.Module):\n",
        "                    def forward(self, x):\n",
        "                        return x.contiguous()\n",
        "\n",
        "                setattr(model, name, nn.Sequential(\n",
        "                    self.dequant,\n",
        "                    ContiguousModule(),\n",
        "                    module,\n",
        "                    self.quant\n",
        "                ))\n",
        "            elif isinstance(module, nn.Sequential):\n",
        "                self.modify_model(module)\n",
        "        return model\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        keep_features = list()\n",
        "        for i, layer in enumerate(self.model.backbone.children()):\n",
        "            # print()\n",
        "            x = layer(x)\n",
        "\n",
        "            if i in [2, 6, 13, 22]:\n",
        "                keep_features.append(x)\n",
        "\n",
        "        global_context = list()\n",
        "        for i, f in enumerate(keep_features):\n",
        "            if i in [0, 1]:\n",
        "                f = nn.AvgPool2d(kernel_size=5, stride=5)(f)\n",
        "            if i in [2]:\n",
        "                f = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))(f)\n",
        "\n",
        "            # Dequantize before torch.pow\n",
        "            f = self.dequant(f)\n",
        "            f_pow = torch.pow(f, 2)\n",
        "            f_mean = torch.mean(f_pow)\n",
        "            f = torch.div(f, f_mean)\n",
        "            # Quantize after torch.div\n",
        "            f = self.quant(f)\n",
        "\n",
        "            global_context.append(f)\n",
        "\n",
        "        x = torch.cat(global_context, 1)\n",
        "        x = self.model.container(x)\n",
        "        logits = torch.mean(x, dim=2)\n",
        "        x = self.dequant(logits).contiguous()\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0MTYuhP9ivX",
        "outputId": "71ceb20d-3c2c-4ad9-f14d-4231da0961c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned LPRNet model deepcopied successfully.\n",
            "Model is on device: cpu\n"
          ]
        }
      ],
      "source": [
        "# prompt: generate a deepcopy of the pruned_lprnet model\n",
        "\n",
        "pruned_lprnet_copy = copy.deepcopy(lprnet)\n",
        "print(\"Pruned LPRNet model deepcopied successfully.\")\n",
        "print(f\"Model is on device: {next(pruned_lprnet_copy.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TZ_UxU2JZGRX"
      },
      "outputs": [],
      "source": [
        "def prepare_for_quantization(model):\n",
        "    model.eval()\n",
        "    model = QuantizableLPRNet(model)\n",
        "    # Function to fuse Conv, BN, and ReLU layers in a Sequential module\n",
        "    def fuse_sequential(sequential):\n",
        "        modules_to_fuse = []\n",
        "        last_conv_index = None\n",
        "\n",
        "        for i in range(len(sequential)):\n",
        "            if isinstance(sequential[i], small_basic_block):\n",
        "                # Find the last Conv2d layer in the small_basic_block\n",
        "                for j, layer in enumerate(sequential[i].block):\n",
        "                    if isinstance(layer, nn.Conv2d):\n",
        "                        last_conv_index = f\"{i}.block.{j}\"\n",
        "            elif last_conv_index is not None:\n",
        "                if isinstance(sequential[i], nn.BatchNorm2d) and \\\n",
        "                  isinstance(sequential[i+1], nn.ReLU):\n",
        "                    modules_to_fuse.append([last_conv_index, str(i), str(i+1)])\n",
        "                    last_conv_index = None\n",
        "                else:\n",
        "                    last_conv_index = None\n",
        "            elif i < len(sequential) - 2:\n",
        "                if isinstance(sequential[i], nn.Conv2d) and \\\n",
        "                  isinstance(sequential[i+1], nn.BatchNorm2d) and \\\n",
        "                  isinstance(sequential[i+2], nn.ReLU):\n",
        "                    modules_to_fuse.append([str(i), str(i+1), str(i+2)])\n",
        "                elif isinstance(sequential[i], nn.Conv2d) and \\\n",
        "                    isinstance(sequential[i+1], nn.BatchNorm2d):\n",
        "                    modules_to_fuse.append([str(i), str(i+1)])\n",
        "\n",
        "        if modules_to_fuse:\n",
        "            torch.quantization.fuse_modules(sequential, modules_to_fuse, inplace=True)\n",
        "\n",
        "    # Fuse layers in the backbone\n",
        "    fuse_sequential(model.model.backbone)\n",
        "\n",
        "    # Fuse layers in the container\n",
        "    fuse_sequential(model.model.container)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fVKRZeqOzJHb"
      },
      "outputs": [],
      "source": [
        "def quantize_model(model):\n",
        "    torch.backends.quantized.engine = 'fbgemm'\n",
        "\n",
        "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "    torch.quantization.prepare(model, inplace=True)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i, (imgs, labels, lengths) in enumerate(test_loader):\n",
        "            if i > 100:  # Calibrate with 100 batches\n",
        "                break\n",
        "            imgs = imgs.to('cpu')  # Quantization requires CPU tensors\n",
        "            a = model(imgs)\n",
        "\n",
        "    # Convert to quantized model\n",
        "    torch.quantization.convert(model, inplace=True)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuZgtHiPzKm9",
        "outputId": "321539f3-55e5-46b4-c8f8-936214fafc3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished quantizing the model\n"
          ]
        }
      ],
      "source": [
        "# Prepare the pruned model for quantization\n",
        "pruned_lprnet_copy = prepare_for_quantization(pruned_lprnet_copy)\n",
        "\n",
        "# Move the model to CPU (quantization requires CPU)\n",
        "pruned_lprnet_copy = pruned_lprnet_copy.cpu()\n",
        "\n",
        "# Quantize the model\n",
        "quantized_lprnet = quantize_model(pruned_lprnet_copy)\n",
        "quantized_lprnet = quantized_lprnet.cpu()\n",
        "\n",
        "print(\"Finished quantizing the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vTIUz3HtLca_"
      },
      "outputs": [],
      "source": [
        "def Greedy_Decode_Eval_quantized(Net, datasets, args):\n",
        "    Net.eval()\n",
        "    Net = Net.cpu()\n",
        "    epoch_size = len(datasets) // args.test_batch_size\n",
        "    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n",
        "\n",
        "    Tp = 0\n",
        "    Tn_1 = 0\n",
        "    Tn_2 = 0\n",
        "    t1 = time.time()\n",
        "    for i in range(epoch_size):\n",
        "        # load train data\n",
        "        images, labels, lengths = next(batch_iterator)\n",
        "        images = images.cpu().contiguous()\n",
        "        start = 0\n",
        "        targets = []\n",
        "\n",
        "        for length in lengths:\n",
        "            label = labels[start:start+length]\n",
        "            targets.append(label)\n",
        "            start += length\n",
        "        targets = np.array([el.numpy() for el in targets])\n",
        "        imgs = images.numpy().copy()\n",
        "\n",
        "        images = Variable(images)\n",
        "\n",
        "        # forward\n",
        "        # forward\n",
        "        with torch.no_grad():\n",
        "          prebs = Net(images)\n",
        "        # greedy decode\n",
        "        prebs = prebs.cpu().detach().numpy()\n",
        "        preb_labels = list()\n",
        "        for i in range(prebs.shape[0]):\n",
        "            preb = prebs[i, :, :]\n",
        "            preb_label = list()\n",
        "            for j in range(preb.shape[1]):\n",
        "                preb_label.append(np.argmax(preb[:, j], axis=0))\n",
        "            no_repeat_blank_label = list()\n",
        "            pre_c = preb_label[0]\n",
        "            if pre_c != len(CHARS) - 1:\n",
        "                no_repeat_blank_label.append(pre_c)\n",
        "            for c in preb_label: # dropout repeate label and blank label\n",
        "                if (pre_c == c) or (c == len(CHARS) - 1):\n",
        "                    if c == len(CHARS) - 1:\n",
        "                        pre_c = c\n",
        "                    continue\n",
        "                no_repeat_blank_label.append(c)\n",
        "                pre_c = c\n",
        "            preb_labels.append(no_repeat_blank_label)\n",
        "        for i, label in enumerate(preb_labels):\n",
        "            # show image and its predict label\n",
        "            if args.show:\n",
        "                show(imgs[i], label, targets[i])\n",
        "            if len(label) != len(targets[i]):\n",
        "                Tn_1 += 1\n",
        "                continue\n",
        "            if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
        "                Tp += 1\n",
        "            else:\n",
        "                Tn_2 += 1\n",
        "    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
        "    t2 = time.time()\n",
        "    return Acc, (t2 - t1) / len(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LzJQKeaR1PHt"
      },
      "outputs": [],
      "source": [
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4GYjlbpuzmIH"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    args = get_parser_test()\n",
        "    quantized_accuracy, quantized_test_speed = Greedy_Decode_Eval_quantized(quantized_lprnet, test_dataset, args)\n",
        "except Exception as e:\n",
        "    print(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slQqie1z3M2U",
        "outputId": "751e503f-f966-4f84-e1c5-baa9a5cedba7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizableLPRNet(\n",
              "  (quant): Quantize(scale=tensor([0.4502]), zero_point=tensor([2]), dtype=torch.quint8)\n",
              "  (dequant): DeQuantize()\n",
              "  (model): LPRNet(\n",
              "    (backbone): Sequential(\n",
              "      (0): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.1549132764339447, zero_point=0)\n",
              "      (1): Identity()\n",
              "      (2): Identity()\n",
              "      (3): Sequential(\n",
              "        (0): DeQuantize()\n",
              "        (1): ContiguousModule()\n",
              "        (2): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "        (3): Quantize(scale=tensor([0.4502]), zero_point=tensor([2]), dtype=torch.quint8)\n",
              "      )\n",
              "      (4): small_basic_block(\n",
              "        (block): Sequential(\n",
              "          (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.42272183299064636, zero_point=71)\n",
              "          (1): ReLU()\n",
              "          (2): QuantizedConv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), scale=0.8551036715507507, zero_point=69, padding=(1, 0))\n",
              "          (3): ReLU()\n",
              "          (4): QuantizedConv2d(32, 32, kernel_size=(1, 3), stride=(1, 1), scale=2.730538845062256, zero_point=42, padding=(0, 1))\n",
              "          (5): ReLU()\n",
              "          (6): QuantizedConvReLU2d(32, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.42173027992248535, zero_point=0)\n",
              "        )\n",
              "      )\n",
              "      (5): Identity()\n",
              "      (6): Identity()\n",
              "      (7): Sequential(\n",
              "        (0): DeQuantize()\n",
              "        (1): ContiguousModule()\n",
              "        (2): MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "        (3): Quantize(scale=tensor([0.4502]), zero_point=tensor([2]), dtype=torch.quint8)\n",
              "      )\n",
              "      (8): small_basic_block(\n",
              "        (block): Sequential(\n",
              "          (0): QuantizedConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.914165198802948, zero_point=60)\n",
              "          (1): ReLU()\n",
              "          (2): QuantizedConv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), scale=1.330651879310608, zero_point=49, padding=(1, 0))\n",
              "          (3): ReLU()\n",
              "          (4): QuantizedConv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), scale=2.2697460651397705, zero_point=58, padding=(0, 1))\n",
              "          (5): ReLU()\n",
              "          (6): QuantizedConvReLU2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.10453463345766068, zero_point=0)\n",
              "        )\n",
              "      )\n",
              "      (9): Identity()\n",
              "      (10): Identity()\n",
              "      (11): small_basic_block(\n",
              "        (block): Sequential(\n",
              "          (0): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.2564221918582916, zero_point=41)\n",
              "          (1): ReLU()\n",
              "          (2): QuantizedConv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), scale=0.3674909770488739, zero_point=66, padding=(1, 0))\n",
              "          (3): ReLU()\n",
              "          (4): QuantizedConv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), scale=0.4292910695075989, zero_point=53, padding=(0, 1))\n",
              "          (5): ReLU()\n",
              "          (6): QuantizedConvReLU2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.4324864149093628, zero_point=0)\n",
              "        )\n",
              "      )\n",
              "      (12): Identity()\n",
              "      (13): Identity()\n",
              "      (14): Sequential(\n",
              "        (0): DeQuantize()\n",
              "        (1): ContiguousModule()\n",
              "        (2): MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "        (3): Quantize(scale=tensor([0.4502]), zero_point=tensor([2]), dtype=torch.quint8)\n",
              "      )\n",
              "      (15): QuantizedDropout(p=0, inplace=False)\n",
              "      (16): QuantizedConvReLU2d(64, 256, kernel_size=(1, 4), stride=(1, 1), scale=0.03321767970919609, zero_point=0)\n",
              "      (17): Identity()\n",
              "      (18): Identity()\n",
              "      (19): QuantizedDropout(p=0, inplace=False)\n",
              "      (20): QuantizedConvReLU2d(256, 68, kernel_size=(13, 1), stride=(1, 1), scale=0.07022607326507568, zero_point=0)\n",
              "      (21): Identity()\n",
              "      (22): Identity()\n",
              "    )\n",
              "    (container): Sequential(\n",
              "      (0): QuantizedConv2d(516, 68, kernel_size=(1, 1), stride=(1, 1), scale=1.7824151515960693, zero_point=91)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "quantized_lprnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "023xN_7u4mIR"
      },
      "source": [
        "#Baseline - TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kfTo5L_wNv8u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tvm\n",
        "from tvm import relay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk2QUgLyUE_A",
        "outputId": "31f8f7e8-07c6-4e79-bb73-b6dc13831ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "args = get_parser_test()\n",
        "test_loader = DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=args.num_workers, collate_fn=collate_fn)\n",
        "sample_input, _, _ = next(iter(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3Jbi9t48Uts5"
      },
      "outputs": [],
      "source": [
        "input_shape = sample_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "id": "IeFoC9wmNy7i"
      },
      "outputs": [],
      "source": [
        "quantized_lprnet = quantized_lprnet.eval()\n",
        "scripted_model = torch.jit.trace(quantized_lprnet, sample_input).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Z8sXLBi5Nz_L"
      },
      "outputs": [],
      "source": [
        "input_name = \"input\"\n",
        "shape_list = [(input_name, input_shape)]\n",
        "mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RxWgtbKsSLJy"
      },
      "outputs": [],
      "source": [
        "target = tvm.target.Target(\"llvm\", host=\"llvm\")\n",
        "dev = tvm.cpu(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFZx_O6BSOD7",
        "outputId": "c348560c-6e74-4894-a1c6-9fa8c7e1dc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autotvm:One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
          ]
        }
      ],
      "source": [
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    lib = relay.build(mod, target=target, params=params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ldBwBzQ_SOTD"
      },
      "outputs": [],
      "source": [
        "from tvm.contrib import graph_executor\n",
        "\n",
        "dtype = \"float32\"\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "l1ZapO9tN4DY"
      },
      "outputs": [],
      "source": [
        "def Greedy_Decode_Eval_TVM(tvm_module, datasets, args):\n",
        "    epoch_size = len(datasets) // args.test_batch_size\n",
        "    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n",
        "\n",
        "    Tp = 0\n",
        "    Tn_1 = 0\n",
        "    Tn_2 = 0\n",
        "    t1 = time.time()\n",
        "\n",
        "    for i in range(epoch_size):\n",
        "        # Load test data\n",
        "        images, labels, lengths = next(batch_iterator)\n",
        "        start = 0\n",
        "        targets = []\n",
        "\n",
        "        for length in lengths:\n",
        "            label = labels[start:start+length]\n",
        "            targets.append(label)\n",
        "            start += length\n",
        "        targets = np.array([el.numpy() for el in targets])\n",
        "        imgs = images.numpy().copy()\n",
        "\n",
        "        tvm_input = tvm.nd.array(images.numpy())\n",
        "        # Set input for TVM module\n",
        "        tvm_module.set_input(\"input\", images.numpy())\n",
        "\n",
        "        # Run inference\n",
        "        tvm_module.run()\n",
        "\n",
        "        # Get output\n",
        "        prebs = tvm_module.get_output(0).asnumpy()\n",
        "\n",
        "        # Greedy decode\n",
        "        preb_labels = list()\n",
        "        for i in range(prebs.shape[0]):\n",
        "            preb = prebs[i, :, :]\n",
        "            preb_label = list()\n",
        "            for j in range(preb.shape[1]):\n",
        "                preb_label.append(np.argmax(preb[:, j], axis=0))\n",
        "            no_repeat_blank_label = list()\n",
        "            pre_c = preb_label[0]\n",
        "            if pre_c != len(CHARS) - 1:\n",
        "                no_repeat_blank_label.append(pre_c)\n",
        "            for c in preb_label: # dropout repeat label and blank label\n",
        "                if (pre_c == c) or (c == len(CHARS) - 1):\n",
        "                    if c == len(CHARS) - 1:\n",
        "                        pre_c = c\n",
        "                    continue\n",
        "                no_repeat_blank_label.append(c)\n",
        "                pre_c = c\n",
        "            preb_labels.append(no_repeat_blank_label)\n",
        "\n",
        "        for i, label in enumerate(preb_labels):\n",
        "            if args.show:\n",
        "                show(imgs[i], label, targets[i])\n",
        "            if len(label) != len(targets[i]):\n",
        "                Tn_1 += 1\n",
        "                continue\n",
        "            if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
        "                Tp += 1\n",
        "            else:\n",
        "                Tn_2 += 1\n",
        "\n",
        "    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
        "    t2 = time.time()\n",
        "    return Acc, (t2 - t1) / len(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "mYOvmvQbOha3"
      },
      "outputs": [],
      "source": [
        "args = get_parser_test()\n",
        "tvmBaseline_accuracy, tvmBaseline_test_speed = Greedy_Decode_Eval_TVM(module, test_dataset, args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TVM Optimization"
      ],
      "metadata": {
        "id": "EtO_aR_5eYWt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGB4-pxDpRzF"
      },
      "source": [
        "# TVM - Autotuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rZUEFqT3yF9v"
      },
      "outputs": [],
      "source": [
        "from tvm import auto_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WiaZNnbWSG5p"
      },
      "outputs": [],
      "source": [
        "# Used to generate tuning_records.json\n",
        "\n",
        "# tasks, task_weights = auto_scheduler.extract_tasks(mod, params, target)\n",
        "# tuner = auto_scheduler.TaskScheduler(tasks, task_weights)\n",
        "# tune_option = auto_scheduler.TuningOptions(\n",
        "#     num_measure_trials=1000,\n",
        "#     measure_callbacks=[auto_scheduler.RecordToFile(\"tuning_records.json\")],\n",
        "#     verbose=2,\n",
        "# )\n",
        "# tuner.tune(tune_option)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relay Quantization"
      ],
      "metadata": {
        "id": "wxXWhyQNehkr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_eMI0tCtpZ0n"
      },
      "outputs": [],
      "source": [
        "with relay.quantize.qconfig(calibrate_mode=\"global_scale\", global_scale=8.0):\n",
        "    mod = relay.quantize.quantize(mod, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv1viBEQ81PC"
      },
      "source": [
        "## Graph Level Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "eBc6Pizmo_NH"
      },
      "outputs": [],
      "source": [
        "from tvm.relay import transform\n",
        "\n",
        "seq = tvm.transform.Sequential(\n",
        "    [\n",
        "        transform.InferType(),\n",
        "        transform.FoldConstant(),\n",
        "        transform.DeadCodeElimination(),\n",
        "        transform.FoldScaleAxis(),\n",
        "    ]\n",
        ")\n",
        "mod = seq(mod)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xzWYgQV9MoD"
      },
      "source": [
        "## Applying Results of Auto-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "e7z89xAXpBmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7696d8b9-f13a-4778-a704-6756c7ac46fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_scheduler:-----------------------------------\n",
            "fused_nn_avg_pool2d_cast_cast_cast_multiply\n",
            "Cannot find tuned schedules for target=llvm -keys=cpu -mtriple=x86_64-redhat-linux-gnu, workload_key=[\"13dee742f86444f84bbf7889ad0ee752\", [100, 32, 20, 90, 4], [100, 32, 4, 18, 4]]. A fallback TOPI schedule is used, which may bring great performance regression or even compilation failure. Compute DAG info:\n",
            "p0 = PLACEHOLDER [100, 32, 20, 90, 4]\n",
            "pool_sum(ax0, ax1, ax2, ax3, ax4) += p0[ax0, ax1, ((ax2*5) + rv0), ((ax3*5) + rv1), ax4]\n",
            "pool_avg(ax0, ax1, ax2, ax3, ax4) = (pool_sum[ax0, ax1, ax2, ax3, ax4]/(((min(((ax2*5) + 4), 19) - (ax2*5)) + 1)*((min(((ax3*5) + 4), 89) - (ax3*5)) + 1)))\n",
            "T_cast(ax0, ax1, ax2, ax3, ax4) = uint8(pool_avg[ax0, ax1, ax2, ax3, ax4])\n",
            "T_cast(ax0, ax1, ax2, ax3, ax4) = int32(T_cast[ax0, ax1, ax2, ax3, ax4])\n",
            "T_cast(ax0, ax1, ax2, ax3, ax4) = float32(T_cast[ax0, ax1, ax2, ax3, ax4])\n",
            "compile_engine_const() = 0.42173f\n",
            "T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_cast[ax0, ax1, ax2, ax3, ax4]*compile_engine_const[])\n",
            "\n",
            "WARNING:auto_scheduler:-----------------------------------\n",
            "fused_nn_avg_pool2d_cast_cast_cast_multiply\n",
            "Cannot find tuned schedules for target=llvm -keys=cpu -mtriple=x86_64-redhat-linux-gnu, workload_key=[\"5749286ddc5bdd2770e5da9297123d94\", [100, 64, 18, 44, 4], [100, 64, 4, 18, 4]]. A fallback TOPI schedule is used, which may bring great performance regression or even compilation failure. Compute DAG info:\n",
            "p0 = PLACEHOLDER [100, 64, 18, 44, 4]\n",
            "pool_sum(ax0, ax1, ax2, ax3, ax4) += p0[ax0, ax1, ((ax2*4) + rv0), ((ax3*2) + rv1), ax4]\n",
            "pool_avg(ax0, ax1, ax2, ax3, ax4) = (pool_sum[ax0, ax1, ax2, ax3, ax4]/(((min(((ax2*4) + 3), 17) - (ax2*4)) + 1)*((min(((ax3*2) + 9), 43) - (ax3*2)) + 1)))\n",
            "T_cast(ax0, ax1, ax2, ax3, ax4) = uint8(pool_avg[ax0, ax1, ax2, ax3, ax4])\n",
            "T_cast(ax0, ax1, ax2, ax3, ax4) = int32(T_cast[ax0, ax1, ax2, ax3, ax4])\n",
            "T_cast(ax0, ax1, ax2, ax3, ax4) = float32(T_cast[ax0, ax1, ax2, ax3, ax4])\n",
            "compile_engine_const() = 1.43249f\n",
            "T_multiply(ax0, ax1, ax2, ax3, ax4) = (T_cast[ax0, ax1, ax2, ax3, ax4]*compile_engine_const[])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with auto_scheduler.ApplyHistoryBest(\"tuning_records.json\"):\n",
        "    with tvm.transform.PassContext(opt_level=3, config={\"relay.backend.use_auto_scheduler\": True}):\n",
        "        lib = relay.build(mod, target=target, params=params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "anomzCIlpFGl"
      },
      "outputs": [],
      "source": [
        "from tvm.contrib import graph_executor\n",
        "\n",
        "dtype = \"float32\"\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "tB9E6FQwpQOg"
      },
      "outputs": [],
      "source": [
        "args = get_parser_test()\n",
        "tvmOptimized_accuracy, tvmOptimized_test_speed = Greedy_Decode_Eval_TVM(module, test_dataset, args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing inference speeds, model size and accuracy"
      ],
      "metadata": {
        "id": "njzr9NttfAW7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsLE7g_5zmuz",
        "outputId": "a39d0cab-b0cb-4016-800f-d9565e169c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model size: 1.81 MB\n",
            "Pruned model size: 1.84 MB\n",
            "Quantized model size: 0.50 MB\n"
          ]
        }
      ],
      "source": [
        "def get_model_size(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size = os.path.getsize(\"temp.p\")\n",
        "    os.remove('temp.p')\n",
        "    return size / 1e6  # Size in MB\n",
        "\n",
        "original_size = get_model_size(lprnet)\n",
        "pruned_size = get_model_size(pruned_lprnet)\n",
        "quantized_size = get_model_size(quantized_lprnet)\n",
        "\n",
        "print(f\"Original model size: {original_size:.2f} MB\")\n",
        "print(f\"Pruned model size: {pruned_size:.2f} MB\")\n",
        "print(f\"Quantized model size: {quantized_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the highest and lowest values\n",
        "lowest_size = min(original_size, pruned_size, quantized_size)\n",
        "highest_size = max(original_size, pruned_size, quantized_size)\n",
        "\n",
        "# Calculate the speedup\n",
        "size_percent_change = ((lowest_size - highest_size) / highest_size) * 100\n",
        "print(f\"The percentage decrease in model size is: {abs(size_percent_change):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soVYi2qV9jbP",
        "outputId": "6e2a514b-e205-4d90-cff0-5a09e6db0a4c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage decrease in model size is: 72.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the highest and lowest values\n",
        "lowest_time = min(baseline_test_speed, pruned_test_speed, quantized_test_speed, tvmBaseline_test_speed, tvmOptimized_test_speed)\n",
        "highest_time = max(baseline_test_speed, pruned_test_speed, quantized_test_speed, tvmBaseline_test_speed, tvmOptimized_test_speed)\n",
        "\n",
        "# Calculate the speedup\n",
        "time_percent_change = ((lowest_time - highest_time) / highest_time) * 100\n",
        "\n",
        "print(f\"The percentage decrease in inference time is: {abs(time_percent_change):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l46tolx1OxO",
        "outputId": "902ba02f-8ef2-47c6-9e6e-d2ecdc464083"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage decrease in inference time is: 91.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highest_accuracy = max(quantized_accuracy, tvmBaseline_accuracy, tvmOptimized_accuracy)\n",
        "\n",
        "accuracy_percent_change = ((highest_accuracy - baseline_accuracy) / baseline_accuracy) * 100\n",
        "\n",
        "print(f\"The percentage decrease in accuracy is: {abs(accuracy_percent_change):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf7MSjQM-dQw",
        "outputId": "c8c0f54d-7fd8-41ff-ba90-8cbc897830c6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage decrease in accuracy is: 16.65%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Zzgy4KPgZwC4",
        "qUt0w5I5LHPu"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}